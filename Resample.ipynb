{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904577a1-0698-4d0a-a512-6ca89f83d0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2020 ssp119_hist.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2020 ssp119_hist.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2020 ssp126.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2020 ssp126.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2020 ssp245.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2020 ssp245.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2020 ssp585.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2020 ssp585.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2030 ssp126.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2030 ssp126.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2030 ssp245.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2030 ssp245.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2030 ssp585.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2030 ssp585.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2050 ssp126.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2050 ssp126.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2050 ssp245.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2050 ssp245.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2050 ssp585.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2050 ssp585.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2100 ssp126.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2100 ssp126.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2100 ssp245.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2100 ssp245.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2100 ssp585.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2100 ssp585.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2150 ssp126.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2150 ssp126.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2150 ssp456.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2150 ssp456.tif\n",
      "Resampling D:\\Earthquake_Project\\GIS processing\\Sea level rise 2150 ssp585.tif -> D:\\Earthquake_Project\\Resampled\\Sea level rise 2150 ssp585.tif\n"
     ]
    }
   ],
   "source": [
    "# batch_resample_to_reference_paths.py\n",
    "# -----------------------------------------------------------\n",
    "# Edit the PATHS section below (already filled with your paths), then run:\n",
    "#   python batch_resample_to_reference_paths.py\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# ============== PATHS (EDIT THESE IF NEEDED) ==============\n",
    "IN_DIR   = r\"D:/Earthquake_Project/GIS processing\"  # folder with rasters to resample\n",
    "REF_PATH = r\"D:/Earthquake_Project/GEM-GSHM_PGA-475y-rock_v2023/v2023_1_pga_475_rock_3min.tif\"  # reference raster\n",
    "OUT_DIR  = r\"D:/Earthquake_Project/Resampled\"       # output folder\n",
    "METHOD   = \"bilinear\"   # choose: \"nearest\" (categorical) | \"bilinear\" | \"cubic\" | \"cubic_spline\" | \"lanczos\"\n",
    "OVERWRITE = True        # set False to skip files that already exist\n",
    "RECURSIVE = False       # set True to include subfolders\n",
    "# ==========================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "\n",
    "# Only interpolation methods (no min/max/average)\n",
    "RESAMPLING_MAP = {\n",
    "    \"nearest\": Resampling.nearest,       # categorical (classes)\n",
    "    \"bilinear\": Resampling.bilinear,     # continuous (default)\n",
    "    \"cubic\": Resampling.cubic,           # continuous\n",
    "    \"cubic_spline\": Resampling.cubic_spline,\n",
    "    \"lanczos\": Resampling.lanczos\n",
    "}\n",
    "\n",
    "def resample_to_match(src_path, ref_path, out_path, resampling=\"bilinear\", compress=\"LZW\"):\n",
    "    \"\"\"\n",
    "    Reproject + resample src raster to EXACTLY match the reference raster's grid.\n",
    "    Interpolation only (nearest/bilinear/cubic/cubic_spline/lanczos).\n",
    "    \"\"\"\n",
    "    src_path, ref_path, out_path = map(Path, (src_path, ref_path, out_path))\n",
    "    if resampling not in RESAMPLING_MAP:\n",
    "        raise ValueError(f\"Invalid resampling '{resampling}'. Choose from {list(RESAMPLING_MAP)}\")\n",
    "    resampling_enum = RESAMPLING_MAP[resampling]\n",
    "\n",
    "    # Reference grid\n",
    "    with rasterio.open(ref_path) as ref_ds:\n",
    "        dst_crs = ref_ds.crs\n",
    "        dst_transform = ref_ds.transform\n",
    "        dst_width = ref_ds.width\n",
    "        dst_height = ref_ds.height\n",
    "\n",
    "    with rasterio.open(src_path) as src_ds:\n",
    "        src_nodata = src_ds.nodata\n",
    "        src_dtype = src_ds.dtypes[0]\n",
    "        count = src_ds.count\n",
    "\n",
    "        # If using interpolating resampling on integer data, promote to float32\n",
    "        out_dtype = src_dtype\n",
    "        if resampling_enum in {Resampling.bilinear, Resampling.cubic,\n",
    "                               Resampling.cubic_spline, Resampling.lanczos} and \\\n",
    "           np.issubdtype(np.dtype(src_dtype), np.integer):\n",
    "            out_dtype = \"float32\"\n",
    "\n",
    "        # Allocate destination array\n",
    "        dst = np.zeros((count, dst_height, dst_width), dtype=out_dtype)\n",
    "\n",
    "        # Reproject/resample band by band\n",
    "        for i in range(1, count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(src_ds, i),\n",
    "                destination=dst[i - 1],\n",
    "                src_transform=src_ds.transform,\n",
    "                src_crs=src_ds.crs,\n",
    "                src_nodata=src_nodata,\n",
    "                dst_transform=dst_transform,\n",
    "                dst_crs=dst_crs,\n",
    "                dst_nodata=src_nodata if np.issubdtype(np.dtype(out_dtype), np.number) else None,\n",
    "                resampling=resampling_enum,\n",
    "            )\n",
    "\n",
    "        # Output profile based on reference grid + source metadata\n",
    "        profile = src_ds.profile.copy()\n",
    "        profile.update(\n",
    "            driver=\"GTiff\",\n",
    "            height=dst_height,\n",
    "            width=dst_width,\n",
    "            transform=dst_transform,\n",
    "            crs=dst_crs,\n",
    "            dtype=out_dtype,\n",
    "            count=count,\n",
    "            tiled=True,\n",
    "            # block sizes must be multiples of 16 to avoid RasterBlockError\n",
    "            blockxsize=256,\n",
    "            blockysize=256,\n",
    "            compress=compress if compress else None,\n",
    "            BIGTIFF=\"IF_SAFER\",\n",
    "        )\n",
    "        # Set nodata sensibly\n",
    "        if np.dtype(out_dtype).kind == \"f\":\n",
    "            profile[\"nodata\"] = np.nan if src_nodata is None else src_nodata\n",
    "        else:\n",
    "            profile[\"nodata\"] = src_nodata\n",
    "\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with rasterio.open(out_path, \"w\", **profile) as dst_ds:\n",
    "            dst_ds.write(dst)\n",
    "\n",
    "def batch_resample_dir(in_dir, ref_path, out_dir, resampling=\"bilinear\", overwrite=False, recursive=False):\n",
    "    \"\"\"\n",
    "    Resample all .tif/.tiff in in_dir to match ref_path, writing to out_dir.\n",
    "    Skips the reference file itself if it lives in the input tree.\n",
    "    \"\"\"\n",
    "    in_dir = Path(in_dir)\n",
    "    out_dir = Path(out_dir)\n",
    "    ref_path = Path(ref_path).resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    patterns = [\"*.tif\", \"*.tiff\", \"*.TIF\", \"*.TIFF\"]  # handle mixed-case extensions\n",
    "    files = []\n",
    "    for pat in patterns:\n",
    "        files += list(in_dir.rglob(pat) if recursive else in_dir.glob(pat))\n",
    "    files = sorted(set(files))  # de-dup if multiple patterns matched same file\n",
    "\n",
    "    if not files:\n",
    "        print(f\"No GeoTIFFs found in {in_dir} (recursive={recursive})\")\n",
    "        return\n",
    "\n",
    "    for src in files:\n",
    "        if src.resolve() == ref_path:\n",
    "            print(f\"Skip reference: {src.name}\")\n",
    "            continue\n",
    "        # Preserve subfolder structure when recursive\n",
    "        rel = src.relative_to(in_dir) if recursive else src.name\n",
    "        out = out_dir / rel\n",
    "        out.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if out.exists() and not overwrite:\n",
    "            print(f\"Skip (exists): {out}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Resampling {src} -> {out}\")\n",
    "        try:\n",
    "            resample_to_match(src, ref_path, out, resampling=resampling)\n",
    "        except Exception as e:\n",
    "            print(f\"FAILED: {src} | {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_resample_dir(\n",
    "        IN_DIR,\n",
    "        REF_PATH,\n",
    "        OUT_DIR,\n",
    "        resampling=METHOD,\n",
    "        overwrite=OVERWRITE,\n",
    "        recursive=RECURSIVE\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10bb4c7-aa81-40ce-a9b8-be88aab7829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: Sea level rise 2020 ssp119_hist.tif\n",
      "Found 15 tiffs to divide.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dividing by reference: 100%|█████████████████████████████████████████████████████████| 15/15 [00:31<00:00,  2.09s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Outputs written to: D:\\Earthquake_Project\\ratios_out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# batch_divide_by_reference.py\n",
    "# --------------------------------------------\n",
    "# For every resampled TIFF in IN_DIR, compute:\n",
    "#   (target_band1) / (reference_band1)\n",
    "# Reference file: \"Sea level rise 2020 ssp119_hist.tif\"\n",
    "# Outputs go to OUT_DIR with suffix \"_ratio_to_ssp119_hist.tif\"\n",
    "# --------------------------------------------\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import reproject\n",
    "from rasterio.windows import Window\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========== EDIT THESE PATHS ==========\n",
    "IN_DIR   = Path(r\"D:/Earthquake_Project/Resampled\")  # folder with all resampled TIFFs\n",
    "OUT_DIR  = Path(r\"D:/Earthquake_Project/ratios_out\")       # where to save ratio tiffs\n",
    "REF_TIF  = Path(r\"D:/Earthquake_Project/Resampled/Sea level rise 2020 ssp119_hist.tif\")\n",
    "# =====================================\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def open_ref(ref_path: Path):\n",
    "    ref = rasterio.open(ref_path)\n",
    "    # Read reference band 1 fully\n",
    "    ref_arr = ref.read(1, masked=True)  # masked array using nodata\n",
    "    ref_meta = ref.meta.copy()\n",
    "    ref_nodata = ref.nodata\n",
    "    return ref, ref_arr, ref_meta, ref_nodata\n",
    "\n",
    "def align_to_ref(src_path: Path, ref_ds, ref_meta):\n",
    "    \"\"\"Read src band1 and align (reproject/resample) to reference grid.\"\"\"\n",
    "    with rasterio.open(src_path) as src:\n",
    "        # Prepare destination array aligned to reference shape/dtype\n",
    "        dst_arr = np.zeros((ref_meta['height'], ref_meta['width']), dtype=np.float32)\n",
    "        dst_arr[:] = np.nan\n",
    "\n",
    "        # Build reproject call\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=dst_arr,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            src_nodata=src.nodata,\n",
    "            dst_transform=ref_ds.transform,\n",
    "            dst_crs=ref_ds.crs,\n",
    "            dst_nodata=np.nan,\n",
    "            resampling=Resampling.nearest  # input is already resampled, so nearest is fine & fast\n",
    "        )\n",
    "        # Return as a masked array where NaN becomes masked\n",
    "        dst_mask = np.isnan(dst_arr)\n",
    "        return np.ma.array(dst_arr, mask=dst_mask)\n",
    "\n",
    "def divide_safe(num_ma, den_ma, den_nodata=None):\n",
    "    \"\"\"Compute num/den with masking where denominator is nodata or zero.\"\"\"\n",
    "    # Start with combined mask of any nodata\n",
    "    mask = np.ma.getmaskarray(num_ma) | np.ma.getmaskarray(den_ma)\n",
    "    den = den_ma.filled(np.nan)\n",
    "\n",
    "    # Also mask where denominator is 0 (avoid divide-by-zero)\n",
    "    zero_mask = (den == 0)\n",
    "    mask = mask | zero_mask\n",
    "\n",
    "    # Perform division\n",
    "    num = num_ma.filled(np.nan)\n",
    "    out = np.divide(num, den, where=~mask, out=np.full_like(num, np.nan, dtype=np.float32)).astype(np.float32)\n",
    "\n",
    "    # Return masked array\n",
    "    return np.ma.array(out, mask=mask)\n",
    "\n",
    "def main():\n",
    "    # --- Load reference once ---\n",
    "    if not REF_TIF.exists():\n",
    "        raise FileNotFoundError(f\"Reference not found: {REF_TIF}\")\n",
    "\n",
    "    ref_ds, ref_arr, ref_meta, ref_nodata = open_ref(REF_TIF)\n",
    "\n",
    "    # Normalize reference to float32 masked array\n",
    "    ref_arr = ref_arr.astype(np.float32)\n",
    "\n",
    "    # Collect candidate tiffs\n",
    "    tiffs = sorted([p for p in IN_DIR.glob(\"*.tif\") if p.is_file()])\n",
    "\n",
    "    # Skip the reference file itself\n",
    "    tiffs = [p for p in tiffs if p.resolve() != REF_TIF.resolve()]\n",
    "\n",
    "    if not tiffs:\n",
    "        print(\"No TIFFs found to process in:\", IN_DIR)\n",
    "        return\n",
    "\n",
    "    print(f\"Reference: {REF_TIF.name}\")\n",
    "    print(f\"Found {len(tiffs)} tiffs to divide.\\n\")\n",
    "\n",
    "    for tif in tqdm(tiffs, desc=\"Dividing by reference\", unit=\"file\"):\n",
    "        try:\n",
    "            # Read/align numerator (current tif) to reference grid\n",
    "            num_ma = align_to_ref(tif, ref_ds, ref_meta)\n",
    "\n",
    "            # Ensure both are masked arrays float32\n",
    "            num_ma = num_ma.astype(np.float32)\n",
    "            den_ma = ref_arr  # already masked float32\n",
    "\n",
    "            # Compute safe ratio\n",
    "            ratio_ma = divide_safe(num_ma, den_ma, ref_nodata)\n",
    "\n",
    "            # Build output path\n",
    "            out_name = tif.stem + \"_ratio_to_ssp119_hist.tif\"\n",
    "            out_path = OUT_DIR / out_name\n",
    "\n",
    "            # Prepare output profile\n",
    "            profile = ref_meta.copy()\n",
    "            profile.update(\n",
    "                dtype=\"float32\",\n",
    "                count=1,\n",
    "                compress=\"lzw\",\n",
    "                tiled=True,\n",
    "                blockxsize=min(256, profile['width']),\n",
    "                blockysize=min(256, profile['height']),\n",
    "                BIGTIFF=\"IF_SAFER\",\n",
    "                nodata=-9999.0\n",
    "            )\n",
    "\n",
    "            # Write\n",
    "            with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "                # Fill masked with nodata value\n",
    "                data_to_write = ratio_ma.filled(profile[\"nodata\"])\n",
    "                dst.write(data_to_write, 1)\n",
    "\n",
    "            # Optional: copy over overviews can be added later if needed\n",
    "            # rasterio.shutil.copyfiles() is not required here.\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[WARN] Failed on {tif.name}: {e}\")\n",
    "\n",
    "    ref_ds.close()\n",
    "    print(\"\\nDone! Outputs written to:\", OUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "debf1e9b-8755-40db-bab8-7ce417c556e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████████████████████████████████████████████████████████████████| 15/15 [00:56<00:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Outputs in: D:/Earthquake_Project/PGA_x_SeaLevel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pga_times_divided_batch_fixed.py\n",
    "import os, glob, warnings\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- EDIT THESE PATHS ----------------\n",
    "PGA_TIF      = r\"D:/Earthquake_Project/GEM-GSHM_PGA-475y-rock_v2023/v2023_1_pga_475_rock_3min.tif\"\n",
    "DIVIDED_DIR  = r\"D:/Earthquake_Project/ratios_out\"\n",
    "OUT_DIR      = r\"D:/Earthquake_Project/PGA_x_SeaLevel\"\n",
    "GLOB_PATTERN = \"*.tif\"\n",
    "# -------------------------------------------------\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "F32_MAX = np.finfo(np.float32).max\n",
    "\n",
    "def safe_nodata_for_float32(nodata_value):\n",
    "    \"\"\"\n",
    "    Return a nodata suitable for float32 outputs.\n",
    "    If nodata is None, NaN is fine for float32.\n",
    "    If nodata is +/-inf, NaN, or beyond float32 range, use NaN.\n",
    "    Otherwise return the value.\n",
    "    \"\"\"\n",
    "    if nodata_value is None:\n",
    "        return np.float32(np.nan)\n",
    "    if not np.isfinite(nodata_value):\n",
    "        return np.float32(np.nan)\n",
    "    if abs(nodata_value) > F32_MAX:\n",
    "        return np.float32(np.nan)\n",
    "    return np.float32(nodata_value)\n",
    "\n",
    "def reproject_to_ref(src_path, ref_profile):\n",
    "    \"\"\"Reproject src raster (band 1) to reference grid defined by ref_profile.\"\"\"\n",
    "    with rasterio.open(src_path) as src:\n",
    "        src_nodata = src.nodata\n",
    "        dst = np.full((ref_profile[\"height\"], ref_profile[\"width\"]), np.nan, dtype=np.float32)\n",
    "\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=dst,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            src_nodata=src_nodata,\n",
    "            dst_transform=ref_profile[\"transform\"],\n",
    "            dst_crs=ref_profile[\"crs\"],\n",
    "            dst_nodata=np.nan,  # standardize to NaN in working grid\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "    return dst  # contains NaNs where source was nodata\n",
    "\n",
    "def process_one(divided_path, pga_arr, pga_valid_mask, ref_profile, out_nodata):\n",
    "    \"\"\"Compute output = PGA * DIVIDED where DIVIDED valid else PGA.\"\"\"\n",
    "    div_arr = reproject_to_ref(divided_path, ref_profile)\n",
    "    div_valid = np.isfinite(div_arr)\n",
    "\n",
    "    out = pga_arr.astype(np.float32).copy()\n",
    "\n",
    "    multiply_mask = pga_valid_mask & div_valid\n",
    "    out[multiply_mask] = (pga_arr[multiply_mask] * div_arr[multiply_mask]).astype(np.float32)\n",
    "\n",
    "    # Keep PGA NoData wherever PGA was invalid\n",
    "    invalid_pga = ~pga_valid_mask\n",
    "    if np.isnan(out_nodata):\n",
    "        out[invalid_pga] = np.nan\n",
    "    else:\n",
    "        out[invalid_pga] = out_nodata\n",
    "\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    with rasterio.open(PGA_TIF) as psrc:\n",
    "        pga_profile = psrc.profile.copy()\n",
    "        pga_arr = psrc.read(1)  # keep original dtype for mask creation\n",
    "        pga_nodata_src = psrc.nodata\n",
    "\n",
    "        # Valid where finite and not equal to declared nodata (if any)\n",
    "        if pga_nodata_src is None:\n",
    "            pga_valid_mask = np.isfinite(pga_arr)\n",
    "        else:\n",
    "            pga_valid_mask = np.isfinite(pga_arr) & (pga_arr != pga_nodata_src)\n",
    "\n",
    "        # Prepare output profile: float32 + safe nodata (NaN if needed)\n",
    "        out_nodata = safe_nodata_for_float32(pga_nodata_src)\n",
    "        pga_profile.update(\n",
    "            dtype=\"float32\",\n",
    "            count=1,\n",
    "            compress=\"LZW\",\n",
    "            predictor=2,\n",
    "            BIGTIFF=\"IF_SAFER\",\n",
    "            nodata=float(out_nodata)  # OK to be NaN for float32\n",
    "        )\n",
    "\n",
    "    divided_paths = sorted(glob.glob(os.path.join(DIVIDED_DIR, GLOB_PATTERN)))\n",
    "    if not divided_paths:\n",
    "        print(\"No divided rasters found. Check DIVIDED_DIR and GLOB_PATTERN.\")\n",
    "        return\n",
    "\n",
    "    for dpath in tqdm(divided_paths, desc=\"Processing\"):\n",
    "        try:\n",
    "            out_arr = process_one(dpath, pga_arr, pga_valid_mask, pga_profile, out_nodata)\n",
    "\n",
    "            base = os.path.splitext(os.path.basename(dpath))[0]\n",
    "            out_name = f\"PGAx_{base}.tif\"\n",
    "            out_path = os.path.join(OUT_DIR, out_name)\n",
    "\n",
    "            with rasterio.open(out_path, \"w\", **pga_profile) as dst:\n",
    "                dst.write(out_arr.astype(np.float32), 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {dpath}: {e}\")\n",
    "\n",
    "    print(f\"Done. Outputs in: {OUT_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43016b0-6bbd-4c79-8c20-3e2bdaf8c8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████████████████████████████████████████████████████████████████| 15/15 [01:50<00:00,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Outputs in: D:/Earthquake_Project/PGA_x_SeaLevel3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pga_times_divided_batch_blended.py\n",
    "# ----------------------------------\n",
    "# Multiplies PGA by a set of ratio rasters, but blends the ratio edges\n",
    "# using a distance-based smoothstep ramp so transitions are soft.\n",
    "\n",
    "import os, glob, warnings\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import distance_transform_edt, gaussian_filter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- EDIT THESE PATHS ----------------\n",
    "PGA_TIF      = r\"D:/Earthquake_Project/GEM-GSHM_PGA-475y-rock_v2023/v2023_1_pga_475_rock_3min.tif\"\n",
    "DIVIDED_DIR  = r\"D:/Earthquake_Project/ratios_out\"   # folder of ratio *.tif files\n",
    "OUT_DIR      = r\"D:/Earthquake_Project/PGA_x_SeaLevel3\"\n",
    "GLOB_PATTERN = \"*.tif\"\n",
    "# ------------- BLENDING PARAMETERS ----------------\n",
    "# Width of the feather band around the ratio edge, in PIXELS.\n",
    "# Increase to make edges softer and wider (e.g., 24–48).\n",
    "BLEND_PX = 32\n",
    "# Small polish blur after blending (0 to disable).\n",
    "POST_GAUSS_SIGMA = 1.0\n",
    "# --------------------------------------------------\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "F32_MAX = np.finfo(np.float32).max\n",
    "\n",
    "def safe_nodata_for_float32(nodata_value):\n",
    "    \"\"\"\n",
    "    Ensure a nodata suitable for float32 outputs.\n",
    "    Prefer NaN if nodata is None, inf, or outside float32 range.\n",
    "    \"\"\"\n",
    "    if nodata_value is None:\n",
    "        return np.float32(np.nan)\n",
    "    if not np.isfinite(nodata_value):\n",
    "        return np.float32(np.nan)\n",
    "    if abs(nodata_value) > F32_MAX:\n",
    "        return np.float32(np.nan)\n",
    "    return np.float32(nodata_value)\n",
    "\n",
    "def reproject_to_ref(src_path, ref_profile):\n",
    "    \"\"\"Reproject src raster (band 1) to reference grid defined by ref_profile.\"\"\"\n",
    "    with rasterio.open(src_path) as src:\n",
    "        src_nodata = src.nodata\n",
    "        dst = np.full((ref_profile[\"height\"], ref_profile[\"width\"]), np.nan, dtype=np.float32)\n",
    "\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=dst,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            src_nodata=src_nodata,\n",
    "            dst_transform=ref_profile[\"transform\"],\n",
    "            dst_crs=ref_profile[\"crs\"],\n",
    "            dst_nodata=np.nan,  # standardize to NaN in working grid\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "    return dst  # contains NaNs where source was nodata\n",
    "\n",
    "def smoothstep01(t):\n",
    "    \"\"\"Cubic Hermite smoothstep mapping t in [0,1] -> [0,1].\"\"\"\n",
    "    return t * t * (3.0 - 2.0 * t)\n",
    "\n",
    "def process_one(divided_path, pga_arr, pga_valid_mask, ref_profile, out_nodata):\n",
    "    \"\"\"Compute blended: PGA * blended_multiplier, preserving PGA nodata.\"\"\"\n",
    "    # 1) Read ratio/divided layer on the PGA grid\n",
    "    div_arr = reproject_to_ref(divided_path, ref_profile)\n",
    "\n",
    "    # 2) Valid mask for the ratio\n",
    "    valid = np.isfinite(div_arr)\n",
    "\n",
    "    # 3) Fill NaNs with 1.0 so \"outside\" leaves PGA unchanged\n",
    "    div_filled = div_arr.copy()\n",
    "    div_filled[~valid] = 1.0\n",
    "\n",
    "    # 4) Distance-based feather around the edge\n",
    "    #    dist_in  > 0 inside valid area; dist_out > 0 outside area\n",
    "    dist_in  = distance_transform_edt(valid)\n",
    "    dist_out = distance_transform_edt(~valid)\n",
    "\n",
    "    # Signed distance: positive inside valid, negative outside\n",
    "    signed = dist_in - dist_out\n",
    "\n",
    "    # Map signed distance to a smooth blend weight in [0,1] over 2*BLEND_PX band\n",
    "    # signed = -BLEND_PX -> w≈0 (use 1.0); signed = +BLEND_PX -> w≈1 (use div_filled)\n",
    "    t = np.clip((signed + BLEND_PX) / (2.0 * BLEND_PX), 0.0, 1.0)\n",
    "    w = smoothstep01(t).astype(np.float32)\n",
    "\n",
    "    # 5) Blend multiplier between div_filled and 1.0 using weight w\n",
    "    multiplier = w * div_filled.astype(np.float32) + (1.0 - w) * 1.0\n",
    "\n",
    "    # 6) Optional tiny Gaussian to polish any banding from the ramp\n",
    "    if POST_GAUSS_SIGMA and POST_GAUSS_SIGMA > 0:\n",
    "        multiplier = gaussian_filter(multiplier, sigma=POST_GAUSS_SIGMA, mode=\"nearest\")\n",
    "\n",
    "    # 7) Multiply PGA only where PGA is valid\n",
    "    out = pga_arr.astype(np.float32).copy()\n",
    "    out[pga_valid_mask] = (pga_arr[pga_valid_mask] * multiplier[pga_valid_mask]).astype(np.float32)\n",
    "\n",
    "    # 8) Keep PGA NoData wherever PGA was invalid\n",
    "    invalid_pga = ~pga_valid_mask\n",
    "    if np.isnan(out_nodata):\n",
    "        out[invalid_pga] = np.nan\n",
    "    else:\n",
    "        out[invalid_pga] = out_nodata\n",
    "\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    with rasterio.open(PGA_TIF) as psrc:\n",
    "        pga_profile = psrc.profile.copy()\n",
    "        pga_arr = psrc.read(1)  # keep original dtype for mask creation\n",
    "        pga_nodata_src = psrc.nodata\n",
    "\n",
    "        # Valid where finite and not equal to declared nodata (if any)\n",
    "        if pga_nodata_src is None:\n",
    "            pga_valid_mask = np.isfinite(pga_arr)\n",
    "        else:\n",
    "            pga_valid_mask = np.isfinite(pga_arr) & (pga_arr != pga_nodata_src)\n",
    "\n",
    "        # Prepare output profile: float32 + safe nodata (NaN if needed)\n",
    "        out_nodata = safe_nodata_for_float32(pga_nodata_src)\n",
    "        pga_profile.update(\n",
    "            dtype=\"float32\",\n",
    "            count=1,\n",
    "            compress=\"LZW\",\n",
    "            predictor=2,\n",
    "            BIGTIFF=\"IF_SAFER\",\n",
    "            nodata=float(out_nodata)  # NaN is fine for float32\n",
    "        )\n",
    "\n",
    "    divided_paths = sorted(glob.glob(os.path.join(DIVIDED_DIR, GLOB_PATTERN)))\n",
    "    if not divided_paths:\n",
    "        print(\"No divided rasters found. Check DIVIDED_DIR and GLOB_PATTERN.\")\n",
    "        return\n",
    "\n",
    "    for dpath in tqdm(divided_paths, desc=\"Processing\"):\n",
    "        try:\n",
    "            out_arr = process_one(dpath, pga_arr, pga_valid_mask, pga_profile, out_nodata)\n",
    "\n",
    "            base = os.path.splitext(os.path.basename(dpath))[0]\n",
    "            out_name = f\"PGAx_{base}.tif\"\n",
    "            out_path = os.path.join(OUT_DIR, out_name)\n",
    "\n",
    "            with rasterio.open(out_path, \"w\", **pga_profile) as dst:\n",
    "                dst.write(out_arr.astype(np.float32), 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {dpath}: {e}\")\n",
    "\n",
    "    print(f\"Done. Outputs in: {OUT_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f370023-e5e2-4441-9d1a-a5b47537f0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/16] Classifying: PGAx_Sea level rise 2020 ssp126_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2020 ssp126_ratio_to_ssp119_hist_zones.tif\n",
      "[2/16] Classifying: PGAx_Sea level rise 2020 ssp245_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2020 ssp245_ratio_to_ssp119_hist_zones.tif\n",
      "[3/16] Classifying: PGAx_Sea level rise 2020 ssp585_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2020 ssp585_ratio_to_ssp119_hist_zones.tif\n",
      "[4/16] Classifying: PGAx_Sea level rise 2030 ssp126_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2030 ssp126_ratio_to_ssp119_hist_zones.tif\n",
      "[5/16] Classifying: PGAx_Sea level rise 2030 ssp245_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2030 ssp245_ratio_to_ssp119_hist_zones.tif\n",
      "[6/16] Classifying: PGAx_Sea level rise 2030 ssp585_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2030 ssp585_ratio_to_ssp119_hist_zones.tif\n",
      "[7/16] Classifying: PGAx_Sea level rise 2050 ssp126_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2050 ssp126_ratio_to_ssp119_hist_zones.tif\n",
      "[8/16] Classifying: PGAx_Sea level rise 2050 ssp245_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2050 ssp245_ratio_to_ssp119_hist_zones.tif\n",
      "[9/16] Classifying: PGAx_Sea level rise 2050 ssp585_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2050 ssp585_ratio_to_ssp119_hist_zones.tif\n",
      "[10/16] Classifying: PGAx_Sea level rise 2100 ssp126_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2100 ssp126_ratio_to_ssp119_hist_zones.tif\n",
      "[11/16] Classifying: PGAx_Sea level rise 2100 ssp245_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2100 ssp245_ratio_to_ssp119_hist_zones.tif\n",
      "[12/16] Classifying: PGAx_Sea level rise 2100 ssp585_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2100 ssp585_ratio_to_ssp119_hist_zones.tif\n",
      "[13/16] Classifying: PGAx_Sea level rise 2150 ssp126_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2150 ssp126_ratio_to_ssp119_hist_zones.tif\n",
      "[14/16] Classifying: PGAx_Sea level rise 2150 ssp456_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2150 ssp456_ratio_to_ssp119_hist_zones.tif\n",
      "[15/16] Classifying: PGAx_Sea level rise 2150 ssp585_ratio_to_ssp119_hist.tif -> PGAx_Sea level rise 2150 ssp585_ratio_to_ssp119_hist_zones.tif\n",
      "[16/16] Classifying: v2023_1_pga_475_rock_3min.tif -> v2023_1_pga_475_rock_3min_zones.tif\n",
      "✅ Done. Saved to: D:/Earthquake_Project/classified_out\n",
      "Classes: 0=SkyBlue, 1=Blue, 2=Green, 3=Yellow, 4=Orange, 5=Red; NoData=255 transparent.\n"
     ]
    }
   ],
   "source": [
    "# batch_classify_zones_colored.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.enums import ColorInterp\n",
    "\n",
    "# ============== PATHS (EDIT THESE) ==============\n",
    "IN_DIR  = r\"D:/Earthquake_Project/PGA_x_SeaLevel_2\"   # folder with input .tif files\n",
    "OUT_DIR = r\"D:/Earthquake_Project/classified_out\"      # output folder\n",
    "# =================================================\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def classify_array(arr, nodata_in=None):\n",
    "    \"\"\"\n",
    "    Zones:\n",
    "      0 = <0.05\n",
    "      1 = 0.05–<0.08\n",
    "      2 = 0.08–<0.16\n",
    "      3 = 0.16–<0.24\n",
    "      4 = 0.24–≤0.32\n",
    "      5 = >0.32\n",
    "    Output NoData will be 255 (separate from classes).\n",
    "    \"\"\"\n",
    "    out = np.full(arr.shape, 255, dtype=np.uint8)  # start as NoData=255\n",
    "    valid = np.isfinite(arr)\n",
    "    if nodata_in is not None:\n",
    "        valid &= (arr != nodata_in)\n",
    "\n",
    "    a = arr[valid]\n",
    "    c = np.zeros(a.shape, dtype=np.uint8)  # class codes 0..5 for valid pixels\n",
    "\n",
    "    c[(a >= 0.00) & (a < 0.05)] = 0\n",
    "    c[(a >= 0.05) & (a < 0.08)] = 1\n",
    "    c[(a >= 0.08) & (a < 0.16)] = 2\n",
    "    c[(a >= 0.16) & (a < 0.24)] = 3\n",
    "    c[(a >= 0.24) & (a <= 0.32)] = 4\n",
    "    c[(a >  0.32)]              = 5\n",
    "\n",
    "    out[valid] = c\n",
    "    return out\n",
    "\n",
    "# ======= COLOR MAP (RGBA) =======\n",
    "# 0 sky blue, 1 blue, 2 green, 3 yellow, 4 orange, 5 red\n",
    "# 255 is NoData (transparent) – not added to palette.\n",
    "COLORMAP = {\n",
    "    0:  (135, 206, 235, 255),   # sky blue\n",
    "    1:  (0,   0,   255, 255),   # blue\n",
    "    2:  (0,   128, 0,   255),   # green\n",
    "    3:  (255, 255, 0,   255),   # yellow\n",
    "    4:  (255, 165, 0,   255),   # orange\n",
    "    5:  (255, 0,   0,   255),   # red\n",
    "}\n",
    "\n",
    "def process_file(in_path, out_path):\n",
    "    with rasterio.open(in_path) as src:\n",
    "        profile = src.profile.copy()\n",
    "        nodata_in = src.nodata\n",
    "\n",
    "        data = src.read(1)\n",
    "        classified = classify_array(data, nodata_in)\n",
    "\n",
    "        profile.update(\n",
    "            dtype=rasterio.uint8,\n",
    "            count=1,\n",
    "            nodata=255  # keep 255 as transparent NoData\n",
    "        )\n",
    "\n",
    "        with rasterio.open(out_path, 'w', **profile) as dst:\n",
    "            dst.write(classified, 1)\n",
    "            try:\n",
    "                dst.write_colormap(1, COLORMAP)\n",
    "                dst.colorinterp = (ColorInterp.palette,)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "def main():\n",
    "    tifs = sorted(glob.glob(os.path.join(IN_DIR, \"*.tif\")))\n",
    "    if not tifs:\n",
    "        print(f\"No .tif files found in: {IN_DIR}\")\n",
    "        return\n",
    "\n",
    "    for i, tif in enumerate(tifs, 1):\n",
    "        base = os.path.splitext(os.path.basename(tif))[0]\n",
    "        out_path = os.path.join(OUT_DIR, f\"{base}_zones.tif\")\n",
    "        print(f\"[{i}/{len(tifs)}] Classifying: {base}.tif -> {os.path.basename(out_path)}\")\n",
    "        process_file(tif, out_path)\n",
    "\n",
    "    print(\"✅ Done. Saved to:\", OUT_DIR)\n",
    "    print(\"Classes: 0=SkyBlue, 1=Blue, 2=Green, 3=Yellow, 4=Orange, 5=Red; NoData=255 transparent.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24eb72b5-020e-452b-983c-ce5c4d000143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/16] Clipped: PGAx_Sea level rise 2020 ssp126_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2020 ssp126_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[2/16] Clipped: PGAx_Sea level rise 2020 ssp245_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2020 ssp245_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[3/16] Clipped: PGAx_Sea level rise 2020 ssp585_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2020 ssp585_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[4/16] Clipped: PGAx_Sea level rise 2030 ssp126_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2030 ssp126_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[5/16] Clipped: PGAx_Sea level rise 2030 ssp245_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2030 ssp245_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[6/16] Clipped: PGAx_Sea level rise 2030 ssp585_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2030 ssp585_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[7/16] Clipped: PGAx_Sea level rise 2050 ssp126_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2050 ssp126_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[8/16] Clipped: PGAx_Sea level rise 2050 ssp245_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2050 ssp245_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[9/16] Clipped: PGAx_Sea level rise 2050 ssp585_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2050 ssp585_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[10/16] Clipped: PGAx_Sea level rise 2100 ssp126_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2100 ssp126_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[11/16] Clipped: PGAx_Sea level rise 2100 ssp245_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2100 ssp245_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[12/16] Clipped: PGAx_Sea level rise 2100 ssp585_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2100 ssp585_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[13/16] Clipped: PGAx_Sea level rise 2150 ssp126_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2150 ssp126_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[14/16] Clipped: PGAx_Sea level rise 2150 ssp456_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2150 ssp456_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[15/16] Clipped: PGAx_Sea level rise 2150 ssp585_ratio_to_ssp119_hist_zones.tif -> PGAx_Sea level rise 2150 ssp585_ratio_to_ssp119_hist_zones_IND.tif\n",
      "[16/16] Clipped: v2023_1_pga_475_rock_3min_zones.tif -> v2023_1_pga_475_rock_3min_zones_IND.tif\n",
      "✅ Done. Outputs saved to: D:/Earthquake_Project/clipped_to_india\n"
     ]
    }
   ],
   "source": [
    "# batch_clip_to_india.py\n",
    "# -----------------------------------------------------------\n",
    "# Edit the PATHS below, then run:\n",
    "#   python batch_clip_to_india.py\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.enums import ColorInterp\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "# ============== PATHS (EDIT THESE) ==============\n",
    "IN_DIR   = r\"D:/Earthquake_Project/classified_out\"      # folder with input .tif files\n",
    "INDIA_SHP = r\"D:/Thesis & Internship/Dissertation/West Bengal/India Shapefile With Kashmir/India Shape/india_st.shp\"   # path to your India shapefile\n",
    "OUT_DIR  = r\"D:/Earthquake_Project/clipped_to_india\"    # output folder\n",
    "# =================================================\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def load_india_geom():\n",
    "    # Read India boundary and dissolve to one multipart polygon\n",
    "    gdf = gpd.read_file(INDIA_SHP)\n",
    "    # if multiple features, dissolve all into one\n",
    "    india = gdf.dissolve()  # dissolves by all rows -> single feature\n",
    "    return india\n",
    "\n",
    "def reproject_geom_to_raster(india_gdf, raster_crs):\n",
    "    # Reproject to raster CRS\n",
    "    if india_gdf.crs is None:\n",
    "        raise ValueError(\"India shapefile has no CRS set. Please define it.\")\n",
    "    india_r = india_gdf.to_crs(raster_crs)\n",
    "    # get geometry as GeoJSON-like mapping\n",
    "    geoms = [mapping(india_r.geometry.iloc[0])]\n",
    "    return geoms\n",
    "\n",
    "def clip_one_tif(in_path, india_gdf):\n",
    "    with rasterio.open(in_path) as src:\n",
    "        # Reproject India geometry to this raster's CRS\n",
    "        geoms = reproject_geom_to_raster(india_gdf, src.crs)\n",
    "\n",
    "        # Preserve input nodata if present; if none and data are classes, you can force 255\n",
    "        out_nodata = src.nodata if src.nodata is not None else None\n",
    "\n",
    "        # Do the mask (crop=True to trim bounds)\n",
    "        clipped, out_transform = mask(\n",
    "            src,\n",
    "            geoms,\n",
    "            crop=True,\n",
    "            filled=True,          # fill outside with nodata\n",
    "            nodata=out_nodata     # keep same nodata; set to 255 manually if you prefer for classes\n",
    "        )\n",
    "\n",
    "        profile = src.profile.copy()\n",
    "        profile.update(\n",
    "            height=clipped.shape[1],\n",
    "            width=clipped.shape[2],\n",
    "            transform=out_transform\n",
    "        )\n",
    "\n",
    "        # If you want to force class nodata to 255 (common for paletted class rasters), uncomment:\n",
    "        # profile.update(nodata=255)\n",
    "        # clipped[clipped == (src.nodata if src.nodata is not None else -999999)] = 255\n",
    "\n",
    "        # Write output, preserving colormap if present\n",
    "        base = os.path.splitext(os.path.basename(in_path))[0]\n",
    "        out_path = os.path.join(OUT_DIR, f\"{base}_IND.tif\")\n",
    "        with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "            dst.write(clipped)\n",
    "\n",
    "            # Preserve color table if the source had one\n",
    "            try:\n",
    "                cm = src.colormap(1)\n",
    "                if cm:\n",
    "                    dst.write_colormap(1, cm)\n",
    "                    dst.colorinterp = (ColorInterp.palette,)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        return out_path\n",
    "\n",
    "def main():\n",
    "    india_gdf = load_india_geom()\n",
    "    tifs = sorted(glob.glob(os.path.join(IN_DIR, \"*.tif\")))\n",
    "    if not tifs:\n",
    "        print(f\"No .tif files found in: {IN_DIR}\")\n",
    "        return\n",
    "\n",
    "    for i, tif in enumerate(tifs, 1):\n",
    "        out_path = clip_one_tif(tif, india_gdf)\n",
    "        print(f\"[{i}/{len(tifs)}] Clipped: {os.path.basename(tif)} -> {os.path.basename(out_path)}\")\n",
    "\n",
    "    print(\"✅ Done. Outputs saved to:\", OUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09e6dd25-431b-473f-b1c9-41dddfbf4fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2020 ssp126_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2020 ssp245_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2020 ssp585_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2030 ssp126_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2030 ssp245_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2030 ssp585_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2050 ssp126_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2050 ssp245_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2050 ssp585_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2100 ssp126_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2100 ssp245_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2100 ssp585_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2150 ssp126_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2150 ssp456_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\PGAx_Sea level rise 2150 ssp585_ratio_to_ssp119_hist_zones_IND_smooth.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pekham_Ganguly\\AppData\\Local\\Temp\\ipykernel_996\\2975672768.py:26: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  india_outline = gdf.unary_union.buffer(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smoothed saved: D:/Earthquake_Project/clipped_to_india_smooth122\\v2023_1_pga_475_rock_3min_zones_IND_smooth.tif\n",
      "🎯 All TIFFs processed — smooth internal edges, India boundary preserved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.features import shapes, rasterize\n",
    "from shapely.geometry import shape\n",
    "import geopandas as gpd\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "IN_DIR  = r\"D:/Earthquake_Project/clipped_to_india\"        \n",
    "OUT_DIR = r\"D:/Earthquake_Project/clipped_to_india_smooth122\" \n",
    "SMOOTH  = 1.5   # increase for more smoothing (try 2, 3, 5)\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def smooth_edges(data, transform, nodata=None):\n",
    "    # Create India mask (all non-nodata area)\n",
    "    india_mask = (data != nodata) if nodata is not None else (data > 0)\n",
    "\n",
    "    # Vectorize zones\n",
    "    results = (\n",
    "        {\"properties\": {\"val\": v}, \"geometry\": s}\n",
    "        for s, v in shapes(data, mask=india_mask, transform=transform)\n",
    "    )\n",
    "    gdf = gpd.GeoDataFrame.from_features(results)\n",
    "\n",
    "    # Save original India outline (outer boundary)\n",
    "    india_outline = gdf.unary_union.buffer(0)\n",
    "\n",
    "    # Smooth polygons using buffer in/out\n",
    "    gdf[\"geometry\"] = gdf.buffer(SMOOTH).buffer(-SMOOTH)\n",
    "\n",
    "    # Clip smoothed polygons back to India outline (keep outer boundary fixed)\n",
    "    gdf[\"geometry\"] = gdf[\"geometry\"].intersection(india_outline)\n",
    "\n",
    "    # Rasterize back (zones preserved)\n",
    "    out_data = rasterize(\n",
    "        [(geom, val) for geom, val in zip(gdf.geometry, gdf[\"val\"]) if geom is not None],\n",
    "        out_shape=data.shape,\n",
    "        transform=transform,\n",
    "        fill=nodata if nodata is not None else 0,\n",
    "        dtype=data.dtype,\n",
    "    )\n",
    "    return out_data\n",
    "\n",
    "# ========== LOOP OVER ALL TIFFS ==========\n",
    "for fname in os.listdir(IN_DIR):\n",
    "    if not fname.lower().endswith(\".tif\"):\n",
    "        continue\n",
    "\n",
    "    in_path  = os.path.join(IN_DIR, fname)\n",
    "    out_path = os.path.join(OUT_DIR, fname.replace(\".tif\", \"_smooth.tif\"))\n",
    "\n",
    "    with rasterio.open(in_path) as src:\n",
    "        data = src.read(1)\n",
    "        profile = src.profile\n",
    "        transform = src.transform\n",
    "        nodata = profile.get(\"nodata\", None)\n",
    "\n",
    "    smoothed = smooth_edges(data, transform, nodata=nodata)\n",
    "\n",
    "    profile.update(dtype=data.dtype)\n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        dst.write(smoothed, 1)\n",
    "\n",
    "    print(f\"✅ Smoothed saved: {out_path}\")\n",
    "\n",
    "print(\"🎯 All TIFFs processed — smooth internal edges, India boundary preserved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37538769-6030-466b-b0a9-88ff02cab265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
