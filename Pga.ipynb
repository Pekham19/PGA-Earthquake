{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de38183-ec1d-411c-a69f-b5f48df77cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pekham_ganguly\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events used: 284,368\n",
      "Grid: 180 x 360 cells (step 1.0°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing annual max PGA per cell: 100%|█████████████████████████████████████| 284368/284368 [01:00<00:00, 4713.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outputs:\n",
      "Base map: D:/Earthquake_Project/pga_outputs\\PGA_hist_max_1950_2025.tif\n",
      "Forecast: D:/Earthquake_Project/pga_outputs\\PGA_forecast_2030.tif\n",
      "Forecast: D:/Earthquake_Project/pga_outputs\\PGA_forecast_2050.tif\n",
      "Forecast: D:/Earthquake_Project/pga_outputs\\PGA_forecast_2100.tif\n",
      "CSVs saved alongside the GeoTIFFs.\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# ---------------- USER SETTINGS ----------------\n",
    "CATALOG_CSV = r\"D:/Earthquake_Project/Datasets/Earthquake_datasets.csv\"  # time, latitude, longitude, depth, mag\n",
    "OUTPUT_DIR  = r\"D:/Earthquake_Project/pga_outputs\"\n",
    "GRID_STEP_DEG = 1.0          # 1.0° (~111 km). Use 0.5 or 0.25 for finer grids (slower).\n",
    "MIN_MAG = 4.5                # ignore tiny events to keep runtime reasonable; set 2.5 if you need all\n",
    "MAX_DIST_KM = 300.0          # only affect cells within this epicentral distance\n",
    "VS30_DEFAULT = 760.0         # rock site proxy (only used implicitly by GMPE coefficients here)\n",
    "YEARS_RANGE = (1950, 2025)   # historical window\n",
    "FORECAST_YEARS = [2030, 2050, 2100]\n",
    "# ------------------------------------------------\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------- LOAD CATALOG ----------------\n",
    "eq = pd.read_csv(CATALOG_CSV)\n",
    "eq.columns = [c.strip().lower() for c in eq.columns]\n",
    "for col in [\"time\",\"latitude\",\"longitude\",\"depth\",\"mag\"]:\n",
    "    if col not in eq.columns: raise ValueError(f\"Missing column: {col}\")\n",
    "\n",
    "eq[\"time\"] = pd.to_datetime(eq[\"time\"], errors=\"coerce\")\n",
    "eq = eq.dropna(subset=[\"time\",\"latitude\",\"longitude\",\"depth\",\"mag\"])\n",
    "eq = eq[(eq[\"time\"].dt.year >= YEARS_RANGE[0]) & (eq[\"time\"].dt.year <= YEARS_RANGE[1])]\n",
    "eq = eq[eq[\"mag\"] >= MIN_MAG].copy()\n",
    "eq[\"year\"] = eq[\"time\"].dt.year.astype(int)\n",
    "\n",
    "print(f\"Events used: {len(eq):,}\")\n",
    "\n",
    "# ---------------- BUILD GLOBAL GRID ----------------\n",
    "lats = np.arange(-90 + GRID_STEP_DEG/2, 90, GRID_STEP_DEG)\n",
    "lons = np.arange(-180 + GRID_STEP_DEG/2, 180, GRID_STEP_DEG)\n",
    "nlat, nlon = len(lats), len(lons)\n",
    "print(f\"Grid: {nlat} x {nlon} cells (step {GRID_STEP_DEG}°)\")\n",
    "\n",
    "years = np.arange(YEARS_RANGE[0], YEARS_RANGE[1]+1, dtype=int)\n",
    "ny = len(years)\n",
    "year_to_idx = {y:i for i,y in enumerate(years)}\n",
    "\n",
    "# store annual MAX PGA per cell (in g)\n",
    "pga_max = np.zeros((ny, nlat, nlon), dtype=np.float32)\n",
    "\n",
    "# quick look-up of grid cell indices by integer bins\n",
    "lat_bins = np.floor(lats).astype(int)\n",
    "lon_bins = np.floor(lons).astype(int)\n",
    "bin_index = {}\n",
    "for i, la in enumerate(lat_bins):\n",
    "    for j, lo in enumerate(lon_bins):\n",
    "        bin_index.setdefault((la, lo), []).append((i, j))\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    # lat/lon in degrees, returns distance in km (vectorized for lat2/lon2 arrays)\n",
    "    d2r = np.pi/180.0\n",
    "    f1, f2 = lat1*d2r, lat2*d2r\n",
    "    dlat = (lat2 - lat1)*d2r\n",
    "    dlon = (lon2 - lon1)*d2r\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(f1)*np.cos(f2)*np.sin(dlon/2.0)**2\n",
    "    return 6371.0 * 2.0 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "\n",
    "# Simple global GMPE-like proxy (OK for big-picture maps; not a design PSHA):\n",
    "# ln(PGA[g]) = c0 + c1*M - c2*ln(R + h), where R ≈ sqrt( (epi-dist)^2 + depth^2 ), h avoids singularity.\n",
    "# Coefficients tuned to produce reasonable g-values at global scale for rock sites.\n",
    "c0, c1, c2, h = -1.5, 0.9, 1.1, 10.0\n",
    "\n",
    "def pga_g_from_M_Rdepth(Mw, R_hyp_km):\n",
    "    ln_pga = c0 + c1*Mw - c2*np.log(R_hyp_km + h)\n",
    "    return np.exp(ln_pga)\n",
    "\n",
    "# ---------------- AGGREGATE PER EVENT ----------------\n",
    "ddeg = MAX_DIST_KM / 111.0   # ~degrees\n",
    "\n",
    "for idx, ev in tqdm(eq.iterrows(), total=len(eq), desc=\"Computing annual max PGA per cell\"):\n",
    "    y = int(ev[\"year\"]); iy = year_to_idx[y]\n",
    "    ev_lat = float(ev[\"latitude\"]); ev_lon = float(ev[\"longitude\"])\n",
    "    dep = max(0.0, float(ev[\"depth\"]))\n",
    "    Mw  = float(ev[\"mag\"])\n",
    "\n",
    "    # candidate bins within bounding box\n",
    "    lat_lo = math.floor(ev_lat - ddeg); lat_hi = math.floor(ev_lat + ddeg)\n",
    "    lon_lo = math.floor(ev_lon - ddeg); lon_hi = math.floor(ev_lon + ddeg)\n",
    "\n",
    "    cand_idx = []\n",
    "    for la in range(lat_lo, lat_hi+1):\n",
    "        for lo in range(lon_lo, lon_hi+1):\n",
    "            if (la, lo) in bin_index:\n",
    "                cand_idx.extend(bin_index[(la, lo)])\n",
    "    if not cand_idx: \n",
    "        continue\n",
    "\n",
    "    # compute great-circle distance only for these candidates\n",
    "    ci, cj = zip(*cand_idx)\n",
    "    lat_arr = lats[np.array(ci)]\n",
    "    lon_arr = lons[np.array(cj)]\n",
    "    dist_km = haversine_km(ev_lat, ev_lon, lat_arr, lon_arr)\n",
    "    mask = dist_km <= MAX_DIST_KM\n",
    "    if not np.any(mask): \n",
    "        continue\n",
    "\n",
    "    ci = np.array(ci)[mask]\n",
    "    cj = np.array(cj)[mask]\n",
    "    dist_sel = dist_km[mask]\n",
    "    R_hyp = np.sqrt(dist_sel**2 + dep**2)\n",
    "\n",
    "    pga_vals = pga_g_from_M_Rdepth(Mw, R_hyp)\n",
    "\n",
    "    # update annual MAX per cell\n",
    "    pga_max[iy, ci, cj] = np.maximum(pga_max[iy, ci, cj], pga_vals.astype(np.float32))\n",
    "\n",
    "# ---------------- HISTORICAL SUMMARY (1950–2025) ----------------\n",
    "# long-term max per cell (useful as base hazard layer)\n",
    "pga_hist_max = np.nanmax(pga_max, axis=0)\n",
    "\n",
    "# ---------------- PER-CELL TREND & FORECAST ----------------\n",
    "# log-linear fit on annual max (small epsilon to avoid log(0))\n",
    "eps = 1e-6\n",
    "x = years.astype(float)\n",
    "X = np.vstack([x, np.ones_like(x)]).T  # for polyfit-like normal equation\n",
    "\n",
    "# prepare output rasters\n",
    "fc_maps = {yr: np.zeros((nlat, nlon), dtype=np.float32) for yr in FORECAST_YEARS}\n",
    "\n",
    "for i in range(nlat):\n",
    "    row = pga_max[:, i, :]  # shape (ny, nlon)\n",
    "    # vectorize across longitudes\n",
    "    for j in range(nlon):\n",
    "        ts = row[:, j]\n",
    "        if np.all(ts == 0): \n",
    "            # no signal; leave zeros\n",
    "            continue\n",
    "        ylog = np.log10(np.maximum(ts, eps))\n",
    "        # mask zeros if too many missing years\n",
    "        valid = np.isfinite(ylog)\n",
    "        if valid.sum() < 10:\n",
    "            # not enough years to fit; use historical max as flat forecast\n",
    "            for yr in FORECAST_YEARS:\n",
    "                fc_maps[yr][i, j] = np.nanmax(ts).astype(np.float32)\n",
    "            continue\n",
    "        xv = x[valid]; yv = ylog[valid]\n",
    "        # linear fit y = a*x + b\n",
    "        a, b = np.polyfit(xv, yv, 1)\n",
    "        for yr in FORECAST_YEARS:\n",
    "            yhat = a*yr + b\n",
    "            fc_maps[yr][i, j] = float(np.power(10.0, yhat))\n",
    "\n",
    "# ---------------- WRITE OUTPUTS (GeoTIFF + CSV) ----------------\n",
    "def write_geotiff(path, arr2d, dtype=\"float32\"):\n",
    "    res_x = GRID_STEP_DEG\n",
    "    res_y = GRID_STEP_DEG\n",
    "    transform = from_origin(lons.min()-res_x/2, lats.max()+res_y/2, res_x, res_y)\n",
    "    with rasterio.open(\n",
    "        path, \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=arr2d.shape[0],\n",
    "        width=arr2d.shape[1],\n",
    "        count=1,\n",
    "        dtype=dtype,\n",
    "        crs=\"EPSG:4326\",\n",
    "        transform=transform,\n",
    "        compress=\"lzw\"\n",
    "    ) as dst:\n",
    "        dst.write(np.flipud(arr2d.astype(dtype)), 1)\n",
    "\n",
    "# Historical base map\n",
    "hist_tif = os.path.join(OUTPUT_DIR, \"PGA_hist_max_1950_2025.tif\")\n",
    "write_geotiff(hist_tif, pga_hist_max)\n",
    "\n",
    "# Forecast maps\n",
    "fc_tifs = []\n",
    "for yr in FORECAST_YEARS:\n",
    "    tif = os.path.join(OUTPUT_DIR, f\"PGA_forecast_{yr}.tif\")\n",
    "    write_geotiff(tif, fc_maps[yr])\n",
    "    fc_tifs.append(tif)\n",
    "\n",
    "# Also save CSVs (grid centers)\n",
    "def save_grid_csv(path, arr2d, colname):\n",
    "    LAT, LON = np.meshgrid(lats, lons, indexing=\"ij\")\n",
    "    df = pd.DataFrame({\n",
    "        \"lat\": LAT.ravel(),\n",
    "        \"lon\": LON.ravel(),\n",
    "        colname: arr2d.ravel()\n",
    "    })\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "save_grid_csv(os.path.join(OUTPUT_DIR, \"PGA_hist_max_1950_2025.csv\"), pga_hist_max, \"pga_g\")\n",
    "for yr in FORECAST_YEARS:\n",
    "    save_grid_csv(os.path.join(OUTPUT_DIR, f\"PGA_forecast_{yr}.csv\"), fc_maps[yr], \"pga_g\")\n",
    "\n",
    "print(\"\\nOutputs:\")\n",
    "print(\"Base map:\", hist_tif)\n",
    "for p in fc_tifs: print(\"Forecast:\", p)\n",
    "print(\"CSVs saved alongside the GeoTIFFs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccaebe5e-2210-4c7b-a9c2-6ff5193dafe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events used: 284,368\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvents used: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(eq)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Add distance feature to earthquake data\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m eq[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdist_to_fault_margin_km\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43meq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnearest_distance_to_geometry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaults_margins\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# 2) Grid\u001b[39;00m\n\u001b[0;32m     87\u001b[0m lats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m90\u001b[39m \u001b[38;5;241m+\u001b[39m GRID_STEP_DEG\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m90\u001b[39m, GRID_STEP_DEG)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:10381\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10367\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10369\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10370\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10371\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10379\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10380\u001b[0m )\n\u001b[1;32m> 10381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 84\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvents used: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(eq)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Add distance feature to earthquake data\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m eq[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdist_to_fault_margin_km\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m eq\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mnearest_distance_to_geometry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaults_margins\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# 2) Grid\u001b[39;00m\n\u001b[0;32m     87\u001b[0m lats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m90\u001b[39m \u001b[38;5;241m+\u001b[39m GRID_STEP_DEG\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m90\u001b[39m, GRID_STEP_DEG)\n",
      "Cell \u001b[1;32mIn[7], line 68\u001b[0m, in \u001b[0;36mnearest_distance_to_geometry\u001b[1;34m(lat, lon, geometry_gdf)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnearest_distance_to_geometry\u001b[39m(lat, lon, geometry_gdf):\n\u001b[0;32m     67\u001b[0m     point \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mpoints_from_xy([lon], [lat])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 68\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43mgeometry_gdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m111\u001b[39m  \u001b[38;5;66;03m# Convert degrees to km (approx.)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distances\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m distances\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopandas\\base.py:4165\u001b[0m, in \u001b[0;36mGeoPandasBase.distance\u001b[1;34m(self, other, align)\u001b[0m\n\u001b[0;32m   4071\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdistance\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4072\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a ``Series`` containing the distance to aligned `other`.\u001b[39;00m\n\u001b[0;32m   4073\u001b[0m \n\u001b[0;32m   4074\u001b[0m \u001b[38;5;124;03m    The operation works on a 1-to-1 row-wise manner:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4163\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopandas\\base.py:86\u001b[0m, in \u001b[0;36m_binary_op\u001b[1;34m(op, this, other, align, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_binary_op\u001b[39m(op, this, other, align, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# type: (str, GeoSeries, GeoSeries, args/kwargs) -> Series[bool/float]\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Binary operation on GeoSeries objects that returns a Series.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     data, index \u001b[38;5;241m=\u001b[39m \u001b[43m_delegate_binary_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Series(data, index\u001b[38;5;241m=\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopandas\\base.py:70\u001b[0m, in \u001b[0;36m_delegate_binary_method\u001b[1;34m(op, this, other, align, *args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(this), \u001b[38;5;28mtype\u001b[39m(other))\n\u001b[1;32m---> 70\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma_this\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, this\u001b[38;5;241m.\u001b[39mindex\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopandas\\array.py:875\u001b[0m, in \u001b[0;36mGeometryArray.distance\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdistance\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_geographic_crs(stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m--> 875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\geopandas\\array.py:780\u001b[0m, in \u001b[0;36mGeometryArray._binary_method\u001b[1;34m(op, left, right, **kwargs)\u001b[0m\n\u001b[0;32m    777\u001b[0m         _crs_mismatch_warn(left, right, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m    778\u001b[0m     right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39m_data\n\u001b[1;32m--> 780\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshapely\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shapely\\decorators.py:88\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[0;32m     87\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shapely\\measurement.py:81\u001b[0m, in \u001b[0;36mdistance\u001b[1;34m(a, b, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;129m@multithreading_enabled\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdistance\u001b[39m(a, b, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the Cartesian distance between two geometries.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import geopandas as gpd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "CATALOG_CSV       = r\"D:/Earthquake_Project/Datasets/Earthquake_datasets.csv\"\n",
    "ACTIVE_FAULTS_MARGINS_SHP = r\"D:/Earthquake_Project/Datasets/Active faults/gem_active_faults.shp\"\n",
    "OUT_DIR           = r\"D:/Earthquake_Project/pga_outputs2\"\n",
    "GRID_STEP_DEG     = 1.0\n",
    "MIN_MAG           = 4.5\n",
    "MAX_DIST_KM       = 300.0\n",
    "YEARS_RANGE       = (1950, 2025)\n",
    "FORECAST_YEARS    = [2030, 2050, 2100]\n",
    "LAGS              = 5          # Set to 3 if RAM is an issue\n",
    "SEED              = 42\n",
    "C0, C1, C2, H     = -1.5, 0.9, 1.1, 10.0     # GMPE-like proxy\n",
    "ACTIVE_CUTOFF     = 1e-6       # Keep cells whose HIST max PGA > this\n",
    "# ============================================\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    d2r = np.pi / 180.0\n",
    "    f1, f2 = lat1*d2r, lat2*d2r\n",
    "    dlat = (lat2-lat1)*d2r\n",
    "    dlon = (lon2-lon1)*d2r\n",
    "    a = np.sin(dlat/2)**2 + np.cos(f1) * np.cos(f2) * np.sin(dlon/2)**2\n",
    "    return 6371.0 * 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "\n",
    "def pga_proxy(Mw, R_hyp_km):\n",
    "    ln_pga = C0 + C1 * Mw - C2 * np.log(R_hyp_km + H)\n",
    "    return np.exp(ln_pga)\n",
    "\n",
    "def write_geotiff(path, arr2d, lats, lons, dtype=\"float32\"):\n",
    "    res_x = lons[1] - lons[0]\n",
    "    res_y = lats[1] - lats[0]\n",
    "    transform = from_origin(lons.min() - res_x/2, lats.max() + res_y/2, res_x, res_y)\n",
    "    with rasterio.open(path, \"w\", driver=\"GTiff\",\n",
    "                       height=arr2d.shape[0], width=arr2d.shape[1],\n",
    "                       count=1, dtype=dtype, crs=\"EPSG:4326\",\n",
    "                       transform=transform, compress=\"lzw\") as dst:\n",
    "        dst.write(np.flipud(arr2d.astype(dtype)), 1)\n",
    "\n",
    "def array_to_csv(path, arr2d, lats, lons, colname=\"pga_g\"):\n",
    "    LAT, LON = np.meshgrid(lats, lons, indexing=\"ij\")\n",
    "    pd.DataFrame({\"lat\": LAT.ravel(), \"lon\": LON.ravel(), colname: arr2d.ravel()}).to_csv(path, index=False)\n",
    "\n",
    "def evaluate(y_true, y_pred, name):\n",
    "    y_true = y_true.astype(np.float32); y_pred = y_pred.astype(np.float32)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{name} -> MAE: {mae:.6f} | RMSE: {rmse:.6f} | R²: {r2:.4f}\")\n",
    "    return {\"model\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "# Load single shapefile for faults and margins\n",
    "faults_margins = gpd.read_file(ACTIVE_FAULTS_MARGINS_SHP)\n",
    "\n",
    "def nearest_distance_to_geometry(lat, lon, geometry_gdf):\n",
    "    point = gpd.points_from_xy([lon], [lat])[0]\n",
    "    distances = geometry_gdf.distance(point) * 111  # Convert degrees to km (approx.)\n",
    "    return distances.min() if not distances.empty else np.nan\n",
    "\n",
    "# 1) Load catalog\n",
    "eq = pd.read_csv(CATALOG_CSV)\n",
    "eq.columns = [c.strip().lower() for c in eq.columns]\n",
    "for col in [\"time\", \"latitude\", \"longitude\", \"depth\", \"mag\"]:\n",
    "    if col not in eq.columns: raise ValueError(f\"Missing column: {col}\")\n",
    "eq[\"time\"] = pd.to_datetime(eq[\"time\"], errors=\"coerce\")\n",
    "eq = eq.dropna(subset=[\"time\", \"latitude\", \"longitude\", \"depth\", \"mag\"])\n",
    "eq = eq[(eq[\"time\"].dt.year >= YEARS_RANGE[0]) & (eq[\"time\"].dt.year <= YEARS_RANGE[1])]\n",
    "eq = eq[eq[\"mag\"] >= MIN_MAG].copy()\n",
    "eq[\"year\"] = eq[\"time\"].dt.year.astype(int)\n",
    "print(f\"Events used: {len(eq):,}\")\n",
    "\n",
    "# Add distance feature to earthquake data\n",
    "eq[\"dist_to_fault_margin_km\"] = eq.apply(lambda row: nearest_distance_to_geometry(row[\"latitude\"], row[\"longitude\"], faults_margins), axis=1)\n",
    "\n",
    "# 2) Grid\n",
    "lats = np.arange(-90 + GRID_STEP_DEG/2, 90, GRID_STEP_DEG)\n",
    "lons = np.arange(-180 + GRID_STEP_DEG/2, 180, GRID_STEP_DEG)\n",
    "nlat, nlon = len(lats), len(lons)\n",
    "years = np.arange(YEARS_RANGE[0], YEARS_RANGE[1]+1, dtype=int)\n",
    "ny = len(years)\n",
    "year_to_idx = {y: i for i, y in enumerate(years)}\n",
    "print(f\"Grid: {nlat} x {nlon} cells\")\n",
    "\n",
    "lat_bins = np.floor(lats).astype(int)\n",
    "lon_bins = np.floor(lons).astype(int)\n",
    "bin_index = {}\n",
    "for i, la in enumerate(lat_bins):\n",
    "    for j, lo in enumerate(lon_bins):\n",
    "        bin_index.setdefault((la, lo), []).append((i, j))\n",
    "\n",
    "# 3) Annual max PGA per cell with distance features\n",
    "pga_year = np.zeros((ny, nlat, nlon), dtype=np.float32)\n",
    "ddeg = MAX_DIST_KM / 111.0\n",
    "for _, ev in eq.iterrows():\n",
    "    y = int(ev[\"year\"]); iy = year_to_idx[y]\n",
    "    ev_lat, ev_lon = float(ev[\"latitude\"]), float(ev[\"longitude\"])\n",
    "    dep = max(0.0, float(ev[\"depth\"])); Mw = float(ev[\"mag\"])\n",
    "    lat_lo = math.floor(ev_lat - ddeg); lat_hi = math.floor(ev_lat + ddeg)\n",
    "    lon_lo = math.floor(ev_lon - ddeg); lon_hi = math.floor(ev_lon + ddeg)\n",
    "    cand = []\n",
    "    for la in range(lat_lo, lat_hi+1):\n",
    "        for lo in range(lon_lo, lon_hi+1):\n",
    "            if (la, lo) in bin_index:\n",
    "                cand.extend(bin_index[(la, lo)])\n",
    "    if not cand: continue\n",
    "    ci, cj = zip(*cand)\n",
    "    ci = np.array(ci); cj = np.array(cj)\n",
    "    dist = haversine_km(ev_lat, ev_lon, lats[ci], lons[cj])\n",
    "    mask = dist <= MAX_DIST_KM\n",
    "    if not np.any(mask): continue\n",
    "    ci = ci[mask]; cj = cj[mask]\n",
    "    R_hyp = np.sqrt(dist[mask]**2 + dep**2)\n",
    "    pga_v = pga_proxy(Mw, R_hyp).astype(np.float32)\n",
    "    pga_year[iy, ci, cj] = np.maximum(pga_year[iy, ci, cj], pga_v)\n",
    "\n",
    "# Historical base & active mask\n",
    "hist_max = np.nanmax(pga_year, axis=0).astype(np.float32)\n",
    "write_geotiff(os.path.join(OUT_DIR, \"PGA_hist_max_1950_2025.tif\"), hist_max, lats, lons)\n",
    "array_to_csv(os.path.join(OUT_DIR, \"PGA_hist_max_1950_2025.csv\"), hist_max, lats, lons)\n",
    "\n",
    "active_mask = hist_max > ACTIVE_CUTOFF\n",
    "print(\"Active cells:\", int(active_mask.sum()), \"of\", nlat*nlon)\n",
    "\n",
    "# 4) Long format + lags (active cells only) with distance features\n",
    "rows = []\n",
    "LAT, LON = np.meshgrid(lats, lons, indexing=\"ij\")\n",
    "for yi, y in enumerate(years):\n",
    "    arr = pga_year[yi]\n",
    "    arr = np.where(active_mask, arr, np.nan)\n",
    "    # Add distance to nearest fault/margin for each grid cell\n",
    "    dist_fault_margin = np.array([[nearest_distance_to_geometry(lat, lon, faults_margins) for lon in lons] for lat in lats])\n",
    "    lat_grid, lon_grid = LAT.ravel(), LON.ravel()\n",
    "    dist_fault_margin_flat = dist_fault_margin.ravel()\n",
    "    rows.append(pd.DataFrame({\n",
    "        \"year\": y,\n",
    "        \"lat\": lat_grid,\n",
    "        \"lon\": lon_grid,\n",
    "        \"pga_g\": arr.ravel(),\n",
    "        \"dist_to_fault_margin_km\": dist_fault_margin_flat\n",
    "    }))\n",
    "long_df = pd.concat(rows, ignore_index=True).dropna(subset=[\"pga_g\"])\n",
    "\n",
    "long_df = long_df.sort_values([\"lat\", \"lon\", \"year\"])\n",
    "for k in range(1, LAGS+1):\n",
    "    long_df[f\"pga_lag{k}\"] = long_df.groupby([\"lat\", \"lon\"])[\"pga_g\"].shift(k)\n",
    "ml_df = long_df.dropna().reset_index(drop=True)\n",
    "\n",
    "# 5) Time-aware split\n",
    "train = ml_df[ml_df[\"year\"] <= 2015].copy()\n",
    "valid = ml_df[(ml_df[\"year\"] > 2015) & (ml_df[\"year\"] <= 2025)].copy()\n",
    "\n",
    "FEATURES = [f\"pga_lag{k}\" for k in range(1, LAGS+1)] + [\"lat\", \"lon\", \"year\", \"dist_to_fault_margin_km\"]\n",
    "TARGET = \"pga_g\"\n",
    "\n",
    "# Downcast to float32 to cut memory\n",
    "X_tr = train[FEATURES].astype(np.float32).values\n",
    "y_tr = train[TARGET].astype(np.float32).values\n",
    "X_va = valid[FEATURES].astype(np.float32).values\n",
    "y_va = valid[TARGET].astype(np.float32).values\n",
    "\n",
    "metrics_rows = []\n",
    "\n",
    "# 6) Random Forest\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=150,\n",
    "    max_depth=12,\n",
    "    max_features=0.6,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    bootstrap=True,\n",
    "    max_samples=0.6,\n",
    "    random_state=SEED,\n",
    "    n_jobs=1\n",
    ")\n",
    "rf.fit(X_tr, y_tr)\n",
    "pred_va_rf = rf.predict(X_va).astype(np.float32)\n",
    "metrics_rows.append(evaluate(y_va, pred_va_rf, \"RandomForest\"))\n",
    "\n",
    "# 7) XGBoost\n",
    "xgb_available = True\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        reg_lambda=1.0,\n",
    "        tree_method=\"hist\",\n",
    "        max_bin=64,\n",
    "        random_state=SEED,\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_jobs=1\n",
    "    )\n",
    "    xgb.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "    pred_va_xgb = xgb.predict(X_va).astype(np.float32)\n",
    "    metrics_rows.append(evaluate(y_va, pred_va_xgb, \"XGBoost\"))\n",
    "except Exception as e:\n",
    "    xgb_available = False\n",
    "    print(\"XGBoost not available, skipping. Reason:\", e)\n",
    "\n",
    "# 8) LSTM\n",
    "lstm_available = True\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models\n",
    "\n",
    "    # Prepare sequences for active cells\n",
    "    seqs_X_tr, seqs_y_tr = [], []\n",
    "    seqs_X_va, seqs_y_va = [], []\n",
    "    for (lat, lon), grp in long_df.groupby([\"lat\", \"lon\"]):\n",
    "        g = grp.sort_values(\"year\")\n",
    "        vals = g[\"pga_g\"].values.astype(\"float32\")\n",
    "        yrs = g[\"year\"].values\n",
    "        dist_fault_margin = g[\"dist_to_fault_margin_km\"].iloc[0]  # Use first value as constant per cell\n",
    "        if len(vals) < (LAGS + 1): continue\n",
    "        for t in range(LAGS, len(vals)):\n",
    "            seq = vals[t-LAGS:t]\n",
    "            target = vals[t]\n",
    "            feat_seq = np.column_stack([seq, [dist_fault_margin] * LAGS])\n",
    "            if yrs[t] <= 2015:\n",
    "                seqs_X_tr.append(feat_seq); seqs_y_tr.append(target)\n",
    "            elif 2016 <= yrs[t] <= 2025:\n",
    "                seqs_X_va.append(feat_seq); seqs_y_va.append(target)\n",
    "\n",
    "    if len(seqs_X_tr) and len(seqs_X_va):\n",
    "        X_tr_seq = np.array(seqs_X_tr, dtype=np.float32)\n",
    "        y_tr_seq = np.array(seqs_y_tr, dtype=np.float32)\n",
    "        X_va_seq = np.array(seqs_X_va, dtype=np.float32)\n",
    "        y_va_seq = np.array(seqs_y_va, dtype=np.float32)\n",
    "\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=(LAGS, 2)),  # Adjusted for lag and fault/margin dist\n",
    "            layers.LSTM(48, return_sequences=False),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "        model.fit(X_tr_seq, y_tr_seq, epochs=5, batch_size=256, verbose=1)\n",
    "\n",
    "        lstm_pred_va = model.predict(X_va_seq, verbose=0).ravel().astype(np.float32)\n",
    "        metrics_rows.append(evaluate(y_va_seq, lstm_pred_va, \"LSTM\"))\n",
    "\n",
    "        # Rolling forecast for LSTM\n",
    "        lstm_state = {}\n",
    "        for (lat, lon), grp in long_df.groupby([\"lat\", \"lon\"]):\n",
    "            g = grp.sort_values(\"year\")\n",
    "            vals = g[g[\"year\"] <= 2025][\"pga_g\"].values.astype(\"float32\")\n",
    "            dist_fault_margin = g[\"dist_to_fault_margin_km\"].iloc[0]\n",
    "            if len(vals) >= LAGS:\n",
    "                lstm_state[(lat, lon)] = list(zip(vals[-LAGS:], [dist_fault_margin] * LAGS))\n",
    "\n",
    "        lstm_fc_grids = {yr: np.full((len(lats), len(lons)), np.nan, dtype=np.float32) for yr in FORECAST_YEARS}\n",
    "        for yr in sorted(FORECAST_YEARS):\n",
    "            for step in range(2026, yr + 1):\n",
    "                for (lat, lon), tail in lstm_state.items():\n",
    "                    if len(tail) < LAGS: continue\n",
    "                    x = np.array([t[0] for t in tail], dtype=np.float32)[None, :, None]  # PGA sequence\n",
    "                    yhat = float(model.predict(x, verbose=0)[0, 0])\n",
    "                    tail.append((yhat, tail[0][1]))  # Append new PGA with same distance\n",
    "                    if len(tail) > LAGS: tail.pop(0)\n",
    "            for (lat, lon), tail in lstm_state.items():\n",
    "                i = np.where(lats == lat)[0]; j = np.where(lons == lon)[0]\n",
    "                if i.size and j.size:\n",
    "                    lstm_fc_grids[yr][i[0], j[0]] = tail[-1][0]\n",
    "\n",
    "        for yr, grid in lstm_fc_grids.items():\n",
    "            write_geotiff(os.path.join(OUT_DIR, f\"PGA_LSTM_{yr}.tif\"), grid, lats, lons)\n",
    "            array_to_csv(os.path.join(OUT_DIR, f\"PGA_LSTM_{yr}.csv\"), grid, lats, lons)\n",
    "    else:\n",
    "        print(\"Not enough sequences for LSTM; skipping.\")\n",
    "except Exception as e:\n",
    "    lstm_available = False\n",
    "    print(\"LSTM step skipped. Reason:\", e)\n",
    "\n",
    "# 9) Rolling forecast for RF and XGB\n",
    "def roll_forecast(model, start_year=2025, target_years=FORECAST_YEARS):\n",
    "    last = long_df[long_df[\"year\"] <= start_year].sort_values([\"lat\", \"lon\", \"year\"])\n",
    "    buff = last.groupby([\"lat\", \"lon\"]).apply(lambda g: list(zip(g[\"pga_g\"].tail(LAGS), g[\"dist_to_fault_margin_km\"].head(1)))).to_dict()\n",
    "    preds = {}\n",
    "    for yr in sorted(target_years):\n",
    "        for y in range(start_year + 1, yr + 1):\n",
    "            feats_rows, idx_rows = [], []\n",
    "            for (lat, lon), tail in buff.items():\n",
    "                if len(tail) < LAGS: continue\n",
    "                row = {f\"pga_lag{k}\": tail[-k][0] for k in range(1, LAGS + 1)}\n",
    "                row.update({\"lat\": lat, \"lon\": lon, \"year\": y, \"dist_to_fault_margin_km\": tail[0][1]})\n",
    "                feats_rows.append(row); idx_rows.append((lat, lon))\n",
    "            if not feats_rows: break\n",
    "            F = pd.DataFrame(feats_rows)[FEATURES].astype(np.float32).values\n",
    "            yhat = model.predict(F).astype(np.float32)\n",
    "            for (lat, lon), val in zip(idx_rows, yhat):\n",
    "                tail = buff[(lat, lon)]\n",
    "                tail.append((float(val), tail[0][1]))\n",
    "                if len(tail) > LAGS: tail.pop(0)\n",
    "        grid = np.full((len(lats), len(lons)), np.nan, dtype=np.float32)\n",
    "        for (lat, lon), tail in buff.items():\n",
    "            i = np.where(lats == lat)[0]; j = np.where(lons == lon)[0]\n",
    "            if i.size and j.size: grid[i[0], j[0]] = tail[-1][0]\n",
    "        preds[yr] = grid\n",
    "    return preds\n",
    "\n",
    "if xgb_available:\n",
    "    xgb_fc = roll_forecast(xgb)\n",
    "    for yr, grid in xgb_fc.items():\n",
    "        write_geotiff(os.path.join(OUT_DIR, f\"PGA_XGB_{yr}.tif\"), grid, lats, lons)\n",
    "        array_to_csv(os.path.join(OUT_DIR, f\"PGA_XGB_{yr}.csv\"), grid, lats, lons)\n",
    "\n",
    "rf_fc = roll_forecast(rf)\n",
    "for yr, grid in rf_fc.items():\n",
    "    write_geotiff(os.path.join(OUT_DIR, f\"PGA_RF_{yr}.tif\"), grid, lats, lons)\n",
    "    array_to_csv(os.path.join(OUT_DIR, f\"PGA_RF_{yr}.csv\"), grid, lats, lons)\n",
    "\n",
    "# 10) Save metrics\n",
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "metrics_path = os.path.join(OUT_DIR, \"model_metrics_validation_2016_2025.csv\")\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "print(\"\\nSaved metrics to:\", metrics_path)\n",
    "print(\"Forecast files saved in:\", OUT_DIR)\n",
    "print(\"Expected outputs include:\")\n",
    "print(\"  - PGA_RF_{2030,2050,2100}.tif / .csv\")\n",
    "if xgb_available:\n",
    "    print(\"  - PGA_XGB_{2030,2050,2100}.tif / .csv\")\n",
    "if lstm_available:\n",
    "    print(\"  - PGA_LSTM_{2030,2050,2100}.tif / .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb973ec8-8426-4e4a-8b57-f2394f26fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
